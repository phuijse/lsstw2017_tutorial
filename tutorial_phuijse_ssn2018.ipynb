{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style>\n",
    ".rendered_html table{\n",
    "    width: 80%;\n",
    "    margin-left:auto; \n",
    "    margin-right:auto;\n",
    "    padding: 20px;\n",
    "    border: 0px solid black;    \n",
    "    background-color: #ff;\n",
    "}\n",
    ".rendered_html td, .rendered_html th \n",
    "{\n",
    "    vertical-align: top;\n",
    "    text-align: left;\n",
    "    font-size: 14px;\n",
    "    font-face: sans-serif;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<h1> Analysis and Classification of Periodic Variable Stars</h1>\n",
    "<h2>Pablo Huijse H. (phuijse at inf dot uach dot cl)</h2>\n",
    "<h3>Universidad Austral de Chile & Millennium Institute of Astrophysics</h3>\n",
    "</center>\n",
    "\n",
    "A tutorial given at the:\n",
    "- [III LSST-Chile Workshop](https://www.lsst-chile.cl/2017-workshop) @ Santiago, Chile, Dec 13-15\n",
    "- [School on Systems and Networks (SSN) 2018](http://niclabs.cl/ssn/2018/) @ Valdivia, Chile, Oct 29-31\n",
    "\n",
    "and running on a jupyterhub at the [NLHPC](http://www.nlhpc.cl/en/) supercomputer *Leftraru*\n",
    "\n",
    "Thanks to: Juan Carlos Maureira (CMM/UChile) and the organizers\n",
    "\n",
    "<a href=\"https://www.space.com/10728-cosmic-visions-paranal-observatory.html\">\n",
    "    <img src=\"img/intro-paranal.jpg\" width=\"800\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variable stars\n",
    "\n",
    "- Stars whose brightness change in time\n",
    "- Different reasons behind this\n",
    "\n",
    "### Pulsating variables\n",
    "- Some variable stars pulsate radially\n",
    "- They expand/heat and contract/cool regularly\n",
    "- Examples: Cepheid and RR Lyrae\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=sXJBrRmHPj8\">\n",
    "    <img src=\"https://media.giphy.com/media/QP4taxvfVmVEI/giphy.gif\" width=\"300\">\n",
    "</a>\n",
    "\n",
    "### Eclipsing Binaries\n",
    "\n",
    "- System of two stars\n",
    "- The rotational plane is aligned with us\n",
    "- From our point of view we see brightness decrease with the mutual eclipses\n",
    "\n",
    "<table>\n",
    "    <tr><td>\n",
    "        <a href=\"http://www.physast.uga.edu/~rls/astro1020/ch16/ovhd.html\">\n",
    "            <img src=\"img/intro-eb.gif\" width=\"300\">\n",
    "        </a>\n",
    "    </td>\n",
    "    <td>\n",
    "        <a href=\"https://en.wikipedia.org/wiki/File:Algol_AB_movie_imaged_with_the_CHARA_interferometer_-_labeled.gif\">\n",
    "            <img src=\"https://media.giphy.com/media/aYb0Ob2GHJ280/giphy.gif\" width=\"300\">\n",
    "        </a>\n",
    "    </td></tr>\n",
    "</table>\n",
    "\n",
    "### Supernovae\n",
    "\n",
    "- Massive star that runs out of fuel\n",
    "- Graviational collapse produces massive explosion\n",
    "- Brightness increases up to 5 billion times our sun\n",
    "\n",
    "<a href=\"http://spaceplasma.tumblr.com/post/74724944019/supernova-explosion-artists-impression-one-of\">\n",
    "    <img src=\"https://media.giphy.com/media/rn79UlSTDfDlS/giphy.gif\" width=\"400\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Light curve\n",
    "\n",
    "- Time series of a star's flux (brightness) on a given passband\n",
    "- The \"apparent\" brightness is estimated through **Photometry**\n",
    "- Variable stars are studied through their light curves\n",
    "\n",
    "<table><tr><td>\n",
    "    <img src=\"img/intro-vista.png\" width=\"250\">\n",
    "</td><td>\n",
    "    <img src=\"img/intro-sources.png\" width=\"300\">\n",
    "</td></tr></table>\n",
    "<img src=\"img/intro-sources-time.png\" width=\"600\">\n",
    "<img src=\"img/intro-lc.png\" width=\"400\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "- Variable stars as distance tracers: **Cosmology**\n",
    "<table>\n",
    "    <tr><td>   \n",
    "        <img src=\"img/period-luminosity-relation.gif\" width=\"400\">\n",
    "    </td><td>\n",
    "        <img src=\"img/intro-milky-way.jpg\" width=\"400\">\n",
    "    </td></tr><tr><td>\n",
    "        <a href=\"http://hyperphysics.phy-astr.gsu.edu/hbase/Astro/dareng.html\">\n",
    "            <img src=\"img/intro-cosmology.gif\" width=\"400\">\n",
    "        </a>\n",
    "    </td><td>\n",
    "        <a href=\"https://owlcation.com/stem/Einstiens-Cosmolgical-Constant-and-the-Expansion-of-the-Universe\">\n",
    "            <img src=\"img/intro-darke.jpg\" width=\"400\">\n",
    "        </a>\n",
    "    </td></tr>\n",
    "</table>\n",
    "\n",
    "- Variable star analysis and classification: **Astrophysics**\n",
    "<a href=\"http://www.atnf.csiro.au/outreach/education/senior/astrophysics/variable_types.html\">\n",
    "    <img src=\"img/variable-star-classification.gif\" width=\"400\">\n",
    "</a>\n",
    "\n",
    "- New methods to analyze astronomical data: **Signal processing** and **Data Science**\n",
    "    - Room for interdisciplinary research\n",
    "    - Astroinformatics and Astrostatistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Part 1: Finding the period of a variable star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import P4J\n",
    "%matplotlib notebook\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'font.size': 12})\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import pickle\n",
    "\n",
    "\n",
    "def fold(mjd, P):\n",
    "    return np.mod(mjd, P)/P\n",
    "\n",
    "def plot_folded(ax, phi, mjd, err):\n",
    "    I = np.argsort(phi)\n",
    "    ax.errorbar(np.concatenate([phi[I], phi[I]+1.]), \n",
    "                np.concatenate([mag[I], mag[I]]),\n",
    "                np.concatenate([err[I], err[I]]), fmt='.', c='k')\n",
    "    ax.invert_yaxis(); ax.grid(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Light curve data inspection\n",
    "\n",
    "- Load a light curve from data folder\n",
    "- Four light curve examples\n",
    "    1. RR Lyrae (Pulsating variable, short period)\n",
    "    - Long Period Variable (LPV) \n",
    "    - Eclipsing binary\n",
    "    - Non-periodic light curve\n",
    "- The columns in the files are the \n",
    "    1. **Modified Julian Data (MJD):** Corresponds to time \n",
    "    - **Magnitude:** Corresponds to apparent brightness (log scale)\n",
    "    - **Error:** Photometric error estimation of the magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print([each for each in listdir('data') if each.endswith('.dat')])\n",
    "# Selected one of the light curves\n",
    "lc_data = np.loadtxt(join('data', 'lc_eb.dat'))\n",
    "# lc_data = np.loadtxt(join('data', 'lc_rrl.dat'))\n",
    "mjd, mag, err = lc_data.T\n",
    "N = len(mjd)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3), tight_layout=True)\n",
    "ax.errorbar(mjd, mag, err, fmt='.', c='k'); ax.invert_yaxis()\n",
    "ax.set_xlabel('MJD'); ax.set_ylabel('Magnitude')\n",
    "ax.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Periodogram\n",
    "\n",
    "- We want to find the period (fundamental frequency) of the star\n",
    "- This is generally done using the **Fourier transform** (FT) or correlation\n",
    "- FT and correlation assumme regular time sampling\n",
    "- Estimating the period with irregular sampling\n",
    "    1. Least squares: Lomb-Scargle periodogram\n",
    "    1. ANOVA periodogram\n",
    "    1. Conditional Entropy and Mutual Information periodograms\n",
    "    1. ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "my_per = P4J.periodogram(method='QMIEU') \n",
    "my_per.set_data(mjd, mag, err, h_KDE_P=0.25)\n",
    "my_per.frequency_grid_evaluation(fmin=0.0, fmax=4.0, fresolution=1e-4)\n",
    "my_per.finetune_best_frequencies(fresolution=1e-5, n_local_optima=10)\n",
    "freq, per = my_per.get_periodogram()\n",
    "fbest, pbest  = my_per.get_best_frequencies()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3), tight_layout=True)\n",
    "ax.plot(freq, per)\n",
    "ax.set_xlabel('Frequency [1/MJD]')\n",
    "ax.set_ylabel('Periodogram')\n",
    "plt.grid()\n",
    "print(\"Best period: %f days\" %(1.0/fbest[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Folding the light curve\n",
    "\n",
    "- Technique used by astronomers to visually inspect periodic variables\n",
    "- You need a candidate period $P$ to perform the folding\n",
    "- The time axis is divided in chucks of size $P$ and plotted on top each other\n",
    "$$\n",
    "\\phi = \\text{modulo}(\\text{MJD}, P)/P\n",
    "$$\n",
    "- If the $P$ is close to the true period you will see a nice periodic shape\n",
    "- Otherwise you see a noisy pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3), tight_layout=True)\n",
    "P = 1.0/fbest[0]\n",
    "plot_folded(ax, np.mod(mjd, P)/P, mag, err)\n",
    "ax.set_xlabel('Phase = 2 pi modulo(MJD, Period)/Period [rad]')\n",
    "ax.set_ylabel('Magnitude'); ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How significant is this period? \n",
    "- The maxima of the periodogram are our test statistic\n",
    "- Do bootstrap resampling to increase our sample of periodogram maxima\"\n",
    "- Fit a Generalized Extreme Value (GEV) distribution (e.g. Gumbel) to the maxima\n",
    "- Find $\\alpha$ confidence threshold for significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import gumbel_r\n",
    "\n",
    "\"\"\"\n",
    "pbest_bootstrap = np.zeros(shape=(10, 100))\n",
    "for i in range(10):\n",
    "    P = np.random.permutation(len(mjd))\n",
    "    my_per.set_data(mjd, mag[P], err[P], h_KDE_P=0.25)\n",
    "    my_per.frequency_grid_evaluation(fmin=0.0, fmax=4.0, fresolution=1e-4)\n",
    "    my_per.finetune_best_frequencies(fresolution=1e-5, n_local_optima=100)\n",
    "    _, pbest_bootstrap[i, :] = my_per.get_best_frequencies()\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 3), tight_layout=True)\n",
    "ax[1].plot(freq, per)\n",
    "ax[1].set_xlabel('Frequency [1/MJD]')\n",
    "ax[1].set_ylabel('Periodogram')\n",
    "param = gumbel_r.fit(pbest_bootstrap.ravel())\n",
    "_ = ax[0].hist(pbest_bootstrap.ravel(), bins=20,\n",
    "               density=True, alpha=0.2, label='Peaks histogram')\n",
    "rv = gumbel_r(loc=param[0], scale=param[1])\n",
    "x = np.linspace(rv.ppf(0.001), rv.ppf(0.999), 100)\n",
    "ax[0].plot(x, rv.pdf(x), 'r-', lw=5, alpha=0.6, label='Fitted Gumbel PDF')\n",
    "ax[0].set_xlim(ax[1].get_ylim())\n",
    "ax[0].set_xlabel('Periodogram value'); ax[0].legend(loc=4);\n",
    "print(\"Best period: %f days\" %(1.0/fbest[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(9, 3), tight_layout=True)\n",
    "ax[0].plot(freq, per)\n",
    "# Print confidence bars\n",
    "xmin, xmax = ax[0].get_xlim()\n",
    "for p_val in [0.999, 0.99, 0.9]:\n",
    "    ax[0].plot([xmin, xmax], [rv.ppf(p_val), rv.ppf(p_val)], \n",
    "               '--', linewidth=4, alpha=0.5, label=str(p_val))\n",
    "ax[0].legend()\n",
    "# Print max of periodogram\n",
    "ymin, ymax = ax[0].get_ylim()\n",
    "ax[0].set_xlim([0., 4.]); ax[0].set_ylim([ymin, ymax]); ax[0].grid(True)\n",
    "ax[0].set_xlabel('Frequency [1/MJD]'); ax[0].set_ylabel('Periodogram')\n",
    "f_fold = fbest[0]; \n",
    "ax[0].plot([f_fold, f_fold], [ymin, ymax], '--', linewidth=4, alpha=0.5)\n",
    "phi = np.mod(mjd, 1.0/f_fold)*f_fold;\n",
    "plot_folded(ax[1], phi, mag, err)\n",
    "ax[1].set_xlabel('Phase @ %0.5f [1/d], %0.5f [d]' %(f_fold, 1.0/f_fold))\n",
    "ax[1].set_ylabel('Magnitude'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning\n",
    "\n",
    "- A paradigm were algorithms **learn** models that map input (data) to a desired response\n",
    "- Roots in statistics\n",
    "- Great success in **pattern recognition** problems: Classification, Regression, Prediction\n",
    "- The user defines the \"family\" of the model and the **learning rules**\n",
    "- The user provides **data and targets**\n",
    "- The user makes sure that the model does not **overfit** the training data\n",
    "- GOAL: **Generalize** to unseen data\n",
    "\n",
    "<img src=\"img/intro-ml.png\" width=\"600\">\n",
    "\n",
    "\n",
    "<a href=\"https://alykhantejani.github.io/a-brief-introduction-to-gradient-descent/\">\n",
    "    <img src=\"img/intro-grad.gif\" width=\"600\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural networks\n",
    "\n",
    "- Neural networks are parametric models loosely based on our brains\n",
    "- Interconnected networks of simple units called neurons \n",
    "- The parameters of the neuron are learnt through solving an optimization problem\n",
    "- Many different architectures to solve many different problems\n",
    "\n",
    "<table><tr><td>\n",
    "    <img src=\"img/intro-neuron.png\" width=\"300\">\n",
    "</td><td>\n",
    "    <img src=\"img/intro-neuron-model.png\" width=\"300\">\n",
    "</td></tr></table>\n",
    "<a href=\"http://www.asimovinstitute.org/neural-network-zoo/\">\n",
    "    <img src=\"img/intro-nns.png\" width=\"600\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Getting features from our periodic light curves\n",
    "\n",
    "- We want to train a neural network to discriminate a particular type of star: **RR Lyrae** \n",
    "- Given that we have the period we train on the folded light curve\n",
    "- To interpolate the folded light curve we use Gaussian processes (GPR) regression\n",
    "\n",
    "### GPR in a nutshell\n",
    "1. Define a kernel (covariance matrix). This sets a functional family for our regressor\n",
    "1. Find the parameters of the kernel by maximum likelihood\n",
    "1. Use the fitted regressor to predict on new samples (interpolation)\n",
    "1. We will use the scikit-learn implementation `sklearn.gaussian_process`\n",
    "\n",
    "<img src=\"img/intro-GP.png\">\n",
    "\n",
    "In practice:\n",
    "- **Note 1:** It is recommended to remove outliers before fitting\n",
    "- **Note 2:** Consider [Heteroscedastic GP regression](http://nbviewer.jupyter.org/github/SheffieldML/notebook/blob/master/GPy/heteroscedastic_regression.ipynb) if error bars differ much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import ExpSineSquared, WhiteKernel\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "gpr = GaussianProcessRegressor(kernel=ExpSineSquared(periodicity=1.0, periodicity_bounds=(0.9999, 1.0001)) \\\n",
    "                               + WhiteKernel(), alpha=err**2, normalize_y=True, n_restarts_optimizer=5)\n",
    "gpr.fit(X=phi[:, np.newaxis], y=mag[:, np.newaxis])\n",
    "print(gpr.kernel_)\n",
    "\n",
    "phi_plot = np.linspace(0.0, 1.0, num=40)[:, np.newaxis]\n",
    "gp_mu, gp_std = gpr.predict(X=phi_plot, return_std=True)\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(7, 4), tight_layout=True)\n",
    "ax[0].plot(np.hstack((phi_plot[:, 0], phi_plot[:, 0]+1)), np.hstack((gp_mu[:, 0], gp_mu[:, 0])))\n",
    "\n",
    "ax[0].fill_between(np.hstack((phi_plot[:, 0], phi_plot[:, 0]+1)), \n",
    "                 np.hstack((gp_mu[:, 0], gp_mu[:, 0])) - 2* np.hstack((gp_std, gp_std)), \n",
    "                 np.hstack((gp_mu[:, 0], gp_mu[:, 0])) + 2* np.hstack((gp_std, gp_std)), alpha=0.5)\n",
    "plot_folded(ax[0], phi, mag, err)\n",
    "ax[0].set_xlabel('Phase'); ax[0].set_ylabel('Magnitude')\n",
    "\n",
    "idx_max = np.argmax(gp_mu); gp_mu = np.roll(gp_mu, -idx_max)\n",
    "ax[1].scatter(np.arange(40), (gp_mu - np.median(gp_mu))/np.std(gp_mu))\n",
    "ax[1].invert_yaxis(); plt.grid()\n",
    "plt.xlabel('Features'); plt.ylabel('Normalized magnitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Part 3: Trainining a neural network\n",
    "\n",
    "1. In this part we will train an [autoencoder](https://docs.google.com/presentation/d/1IJ2n8X4w8pvzNLmpJB-ms6-GDHWthfsJTFuyUqHfXg8/edit?usp=sharing) to visualize the feature space \n",
    "- We will use [PyTorch](https://pytorch.org/) to create and train the model\n",
    "- We have light curves labeled as RR Lyrae and light curves with no label\n",
    "- Can we find unlabeled light curves that belong to the RR Lyrae class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from vae import VAE, live_metric_plotter\n",
    "\n",
    "# Load GP features computed offline\n",
    "lc_periods = pickle.load(open(\"data/lc_periods.pkl\", \"rb\"))\n",
    "data_P = pickle.load(open(\"data/features_P.pkl\", \"rb\"))\n",
    "data_U = pickle.load(open(\"data/features_U.pkl\", \"rb\"))\n",
    "\n",
    "# Split data intro train and validation sets\n",
    "data = np.concatenate((data_P, data_U), axis=0)\n",
    "labels = np.concatenate((np.ones(shape=(len(data_P), 1)), np.zeros(shape=(len(data_U), 1))))\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=0)\n",
    "train_idx, valid_idx = next(sss.split(data, labels))\n",
    "train_dataset = TensorDataset(torch.from_numpy(data[train_idx].astype('float32')))\n",
    "valid_dataset = TensorDataset(torch.from_numpy(data[valid_idx].astype('float32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "batch_size_, nepochs, mc_samples = 32, 50, 32\n",
    "torch.manual_seed(0)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size_, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size_, shuffle=False)\n",
    "\n",
    "model = VAE(n_input=47, n_hidden=16, n_latent=2, importance_sampling=True)\n",
    "print(model)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "print(\"Number of trainable parameters: %d\" %(sum([np.prod(p.size()) for p in model_parameters])))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "plotter = live_metric_plotter()\n",
    "metrics = np.zeros(shape=(nepochs, 2, 2))\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    # Train \n",
    "    for x_batch, in train_loader:\n",
    "        optimizer.zero_grad()        \n",
    "        dec_mu, dec_logvar, enc_mu, enc_logvar, z = model.forward(x_batch, mc_samples)\n",
    "        loss, rec_loss, reg_loss = model.ELBO(x_batch.unsqueeze(1), dec_mu, dec_logvar, enc_mu, enc_logvar, z)        \n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)        \n",
    "        optimizer.step()\n",
    "        metrics[epoch, 0, 0] += rec_loss.detach().numpy()/len(train_dataset)\n",
    "        metrics[epoch, 0, 1] += reg_loss.detach().numpy()/len(train_dataset)\n",
    "    # Test\n",
    "    for x_batch, in valid_loader:\n",
    "        dec_mu, dec_logvar, enc_mu, enc_logvar, z = model.forward(x_batch, mc_samples)\n",
    "        loss, rec_loss, reg_loss = model.ELBO(x_batch.unsqueeze(1), dec_mu, dec_logvar, enc_mu, enc_logvar, z)\n",
    "        metrics[epoch, 1, 0] += rec_loss.detach().numpy()/len(valid_dataset)\n",
    "        metrics[epoch, 1, 1] += reg_loss.detach().numpy()/len(valid_dataset)\n",
    "    \n",
    "    if epoch > 0:\n",
    "        plotter.update(epoch, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dec_mu, test_dec_logvar, test_enc_mu, test_enc_logvar, test_z = model.forward(valid_dataset.tensors[0], k=10)\n",
    "test_enc_mu, test_enc_sigma = test_enc_mu.detach().numpy(), (test_enc_logvar.detach()*0.5).exp().numpy()\n",
    "test_dec_mu = test_dec_mu.detach().numpy()\n",
    "\n",
    "\"\"\"\n",
    "The figure shows the digits in latent space as a dot (mean of the variational posterior) with \n",
    "errorbars (standard deviation of the variational posterior). Each point is a distribution!\n",
    "\"\"\"\n",
    "fig = plt.figure(figsize=(10, 5), dpi=80)\n",
    "ax_main = plt.subplot2grid((2, 3), (0, 0), colspan=2, rowspan=2)\n",
    "ax_ori = plt.subplot2grid((2, 3), (0, 2))\n",
    "ax_rec = plt.subplot2grid((2, 3), (1, 2))\n",
    "a, b, c = ax_main.errorbar(x=test_enc_mu[:, 0], y=test_enc_mu[:, 1], \n",
    "                           xerr=test_enc_sigma[:, 0], yerr=test_enc_sigma[:, 1], \n",
    "                           fmt='none', alpha=0.5, zorder=-1)\n",
    "sc = ax_main.scatter(test_enc_mu[:, 0], test_enc_mu[:, 1], s=2, alpha=0.5, \n",
    "                     c=labels[valid_idx, 0], cmap=plt.cm.RdBu)\n",
    "clb = plt.colorbar(sc, ax=ax_main)\n",
    "for i in range(2):\n",
    "    c[i].set_color(clb.to_rgba(labels[valid_idx, 0]))\n",
    "    \n",
    "ax_ori.plot(np.arange(40), data[valid_idx][0][:40], linewidth=2); \n",
    "ax_rec.errorbar(np.arange(40), np.mean(test_dec_mu[0], axis=0)[:40], \n",
    "                2*np.std(test_dec_mu[0], axis=0)[:40], linewidth=2); \n",
    "for ax in [ax_rec, ax_ori]:\n",
    "    ax.invert_yaxis();\n",
    "    ax.set_ylim([2.5, -1.5]); \n",
    "    \n",
    "c_lim, r_lim = ax_main.get_xlim(), ax_main.get_ylim()\n",
    "plt.tight_layout()\n",
    "\n",
    "def onclick(event):\n",
    "    z_closest = [event.xdata, event.ydata]\n",
    "    print(z_closest)\n",
    "    idx = np.argmin(np.sum((test_enc_mu - z_closest)**2, axis=1))\n",
    "    ax_ori.cla(); ax_ori.set_title(\"Idx:%d, Label:%d\" %(idx, labels[valid_idx][idx, 0]))\n",
    "    ax_ori.plot(np.arange(40), data[valid_idx][idx][:40], linewidth=2); \n",
    "    ax_ori.invert_yaxis(); \n",
    "    # lc_single = lc_raw[valid_idx[idx]]; period_single = lc_period_raw[valid_idx[idx]]\n",
    "    # mean =  np.median(lc_single[:,1]); std = np.std(lc_single[:,1])\n",
    "    #ax_ori.errorbar(40*np.mod(lc_single[:,0], period_single)/period_single, \n",
    "    #                (lc_single[:,1] - mean)/std, lc_single[:,2]/std,fmt='.', c='k')\n",
    "    ax_rec.cla(); ax_rec.invert_yaxis(); ax_rec.set_ylim([2.5, -1.5]); \n",
    "    ax_rec.errorbar(np.arange(40), np.mean(test_dec_mu[idx], axis=0)[:40], \n",
    "                    2*np.std(test_dec_mu[idx], axis=0)[:40], linewidth=2); \n",
    "    \n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick);"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
